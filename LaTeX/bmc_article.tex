

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}
\usepackage{graphicx}
\usepackage{amsmath}
%\usepackage{caption}
%\usepackage{subcaption}

\usepackage{mdframed}
\usepackage{upgreek}
\newcommand{\E}[1]{\underset{#1}{E}}
\newcommand{\Var}[1]{\underset{#1}{Var}}
\usepackage[utf8]{inputenc} 
\def\includegraphic{}
\def\includegraphics{}

%%% Put your definitions there:
\startlocaldefs
\endlocaldefs

%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%\title{ Efficient Estimation of Genomic Breeding Values via Multivariate Ridge Regression }

\title{ New approach fits multivariate genomic prediction models efficiently }

\author[
   addressref={aff1,aff2},
   corref={aff1,aff2},
   noteref={n1},
   email={alencar.xavier@corteva.com}
]{\inits{AX}\fnm{Alencar} \snm{Xavier}}
\author[
   addressref={aff1},
   email={david.habier@corteva.com}
]{\inits{DH}\fnm{David} \snm{Habier}}


\address[id=aff1]{
\orgname{Biostatistics, Corteva Agrisciences},
  \street{8305 NW 62nd Ave},
  \postcode{50131},
  \city{Johnston, Iowa},
  \cny{USA}
}

\address[id=aff2]{
  \orgname{Department of Agronomy,Purdue University},
  \street{915 W State St},
  \postcode{47907},
  \city{West Lafayette, Indiana},
  \cny{USA}
}


\begin{artnotes}
\note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}
\end{fmbox}% comment this for two column layout

\begin{abstractbox}

\begin{abstract} % abstract

\parttitle{Background} Fast, memory-efficient, and reliable algorithms for estimating genomic estimated breeding values (GEBVs) for multiple traits and environments are needed to make timely decisions in breeding. Multivariate genomic prediction exploits genetic correlations between traits and environments to increase accuracy of GEBVs compared to univariate methods. These genetic correlations are estimated simultaneously with GEBVs, because they are specific to year, environment, and management. However, estimating genetic parameters is computationally demanding with restricted maximum likelihood (REML) and Bayesian samplers, and canonical transformations or orthogonalizations cannot be used for unbalanced experimental designs. 

\parttitle{Methods} We propose a multivariate randomized Gauss-Seidel algorithm for simultaneous estimation of model effects and genetic parameters. Two previously proposed methods for estimating genetic parameters were combined with a Gauss-Seidel (GS) solver, and were called \textsl{Tilde-Hat}-GS (THGS) and \textsl{Pseudo-Expectation}-GS (PEGS). Balanced and unbalanced experimental designs were simulated to compare runtime, bias and accuracy of GEBVs, and bias and standard errors of estimates of heritabilities and genetic correlations of THGS, PEGS, and REML. Models with 10 to 400 response variables, 1279 to 42,034 genetic markers, and 5990 to 1.85 million observations were fitted.

\parttitle{Results} Runtime of PEGS and THGS was a fraction of REML. Accuracies of GEBVs were slightly lower than those from REML, but higher than those from the univariate approach, hence THGS and PEGS exploited genetic correlations. For 500 to 600 observations per response variable, biases of estimates of genetic parameters of THGS and PEGS were small, but standard errors of estimates of genetic correlations were higher than for REML. Bias and standard errors decreased as sample size increased.  For balanced designs, GEBVs and estimates of genetic correlations from THGS were unbiased when only an intercept and eigenvectors of genotype scores were fitted.

\parttitle{Conclusions} THGS and PEGS are fast and memory-efficient algorithms for multivariate genomic prediction for balanced and unbalanced experimental designs. They are scalable for increasing numbers of environments and genetic markers. Accuracy of GEBVs was comparable to REML. Estimates of genetic parameters had little bias, but their standard errors were larger than for REML. More studies are needed to evaluate the proposed methods for datasets that contain selection.

\end{abstract}

\end{abstractbox}

\end{frontmatter}

\section{Background}

Genomic prediction \cite{Meuwissen2001} uses genetic markers across the genome to predict complex diseases in humans and breeding values in animals and plants \cite{WGR2013,Hickey2017}. Contrary to univariate analyses, multivariate genomic prediction \cite{Calus2011} 
%by linear mixed-models 
exploits genetic correlations among response variables to increase prediction accuracy for each variable \cite{yi2012}. In plant breeding, these response variables come from different quantitative traits that are measured in different field locations and years. Variance components and genetic correlations are estimated simultaneously with breeding values, because they vary across years, 
locations, and management. In animal breeding, in contrast, variance components are  estimated infrequently within a breeding program and are used to solve mixed-model equations repeatedly over years.

Estimation of variances and covariances can be computationally demanding with standard multivariate approaches for trials with multiple quantitative traits and environments. In restricted maximum likelihood (REML) analyses, large and dense mixed-model equations need to be stored in memory and inverted repeatedly. In Bayesian analyses, model effects need to be sampled for thousands of Markov chain Monte Carlo (MCMC) iterations. This becomes time-consuming with an increasing number of response variables, because increasingly large matrices need to be inverted and factorized in each iteration. Canonical transformation \cite{Meyer1985} or diagonalization of genomic relationship matrices \cite{TS1990} can only be applied to balanced experimental designs when individuals are phenotyped in all environments and for all quantitative traits. However, unbalanced experimental designs are common. A solution would be to estimate genetic correlations for pairs of environments using bivariate models, but this also requires considerable  computation resources. Moreover, the heritabilities of harvest yield are often low (0.1-0.2), so that the precision of estimated variance components for yield can be increased by analyzing yield together with higher heritable traits.

Fast and reliable algorithms are economically important in plant breeding enterprises to make timely decisions and advance the breeding pipeline. With any kind of delays during harvest season, e.g., due to weather, only a few hours may be available for selection decisions. If a breeder misses a deadline to request either new breeding crosses from nurseries or seed of selected individuals or seed of test-crosses, the generation interval increases, genetic gain per year decreases, and product launches are delayed. 

To speed up computations and provide estimated breeding values on time, we propose to combine a randomized Gauss-Seidel \cite{LL2010,Ma2015} solver for updating the effects of a multivariate model with an efficient approach for updating variances and covariances in each iteration of the algorithm. This approach calculates quadratic forms of random effects that resemble those used in REML but are equated to expectations that are easier to compute, as first proposed by \cite{CunninghamHenderson1968, Thompson1969}. Similar approximations have been proposed over the years, as depicted in \cite{VanRaden}, who compared their \textsl{Tilde-Hat} approach to the methods of Schaeffer \cite{Schaeffer} and Henderson \cite{Henderson1980}.

Statistical models that fit either a genomic relationship matrix or marker effects have been proposed for genomic prediction \cite{WGR2013}. The latter is favored when the number of individuals exceeds the number of markers. In closed breeding programs, effective population sizes are such that a moderate number of markers, e.g. 10,000, is sufficient to estimate breeding values using training datasets with a larger number of individuals, e.g. 100,000.

%Literature to efficiently solve multivariate marker effects is scarce. -- THAT SENTENCE HAD BEEN ADDED TO ATTEND A REVIEWER'S REQUEST

The objective of this study was to present and evaluate a multivariate ridge regression approach that uses jointly a randomized Gauss-Seidel solver to estimate marker effects and the methods of either VanRaden \cite{VanRaden} or Schaeffer \cite{Schaeffer} to estimate variances and covariances. Bias and accuracy of genomic estimated breeding values (GEBV) and runtime were studied by simulation of different scenarios, using a wheat dataset from CIMMYT's Global Wheat Program and a soybean dataset from the SoyNAM project. The proposed methods were compared to standard software implementations of REML and univariate analyses to show that the approximations harness the benefits of multivariate models for prediction accuracy. Bayesian Gibbs sampling was added to compare runtime. To understand and interpret differences in bias and accuracy of GEBVs between methods, biases and standard errors of estimates of heritabilities and genetic correlations were evaluated. 

\section{Methods}

\subsection{Statistical model\label{StatModel}}

The multivariate ridge regression model can be written as
\begin{equation}\label{eqn:StatModel}
\mathbf{y} = \mathbf{X}\mathbf{b} + \mathbf{Z}\mathbf{\upbeta} + \mathbf{e},
\end{equation}
where $\mathbf{y}$ is a vector of phenotypes from $K$ environments, which can be partitioned into $\mathbf{y}' = [\mathbf{y}'_1 ~ \mathbf{y}'_2 ~ \hdots \mathbf{y}'_K]$, and each vector $\mathbf{y}'_k$ has length $n_k$;
$\mathbf{X} = \oplus_{k=1}^{K}\mathbf{X}_k$, $\oplus$ denotes the direct sum operator, $\mathbf{X}_k$ is an $n_k$$\times$$r_k$ matrix with full column rank of $r_k$ fixed effects; $\mathbf{b}' = [\mathbf{b}'_1 ~ \mathbf{b}'_2 ~ \hdots \mathbf{b}'_K]$ is a vector of fixed effects for all environments, and each vector $\mathbf{b}'_k$ has length $r_k$;
$\mathbf{Z} = \oplus_{k=1}^{K}\mathbf{Z}_k$, $\mathbf{Z}_k$ is an $n_k$$\times$$m$ matrix that contains marker scores of $n_k$ individuals with phenotypes in environment $k$ and $m$ markers; $\mathbf{\upbeta}' = [\mathbf{\upbeta}'_1 ~ \mathbf{\upbeta}'_2 ~ \hdots \mathbf{\upbeta}'_K]$ is an ($m\cdot K$)-vector of random marker effects for all environments, and each vector $\mathbf{\upbeta}'_k$ has length $m$; $\mathbf{e}' = [\mathbf{e}'_1 ~ \mathbf{e}'_2 ~ \hdots \mathbf{e}'_K]$ is a vector of residuals, and each vector $\mathbf{e}'_k$ has length $n_k$. 
Marker effects are assumed to be multivariate-normal distributed with mean zero and variance-covariance matrix $Var(\mathbf{\upbeta}) = \mathbf{\Sigma}_{\upbeta}\otimes\mathbf{I}_{m}$, where $\mathbf{\Sigma}_{\upbeta}$ is a $K$$\times$$K$ matrix of genetic variances of marker effects, $\sigma^2_{\upbeta_k}$, on the diagonal, and genetic covariances between marker effects from different environments, $\sigma_{\upbeta_{kk'}}$, on the off-diagonal, $\otimes$ is the Kronecker product operator, and $\mathbf{I}_m$ is an identity matrix of dimension $m$. Residuals are assumed to be uncorrelated between environments, and normal distributed with mean zero and variance $Var(\mathbf{e}) = \oplus_{k=1}^K\mathbf{I}_k\sigma^2_{e_k}$.

\subsection{Solving fixed effects and marker effects}

The mixed-model equations can be written as:
\begin{equation}\nonumber
\label{eqn:MME}
\begin{bmatrix}
\mathbf{X}'_1\mathbf{X}_1\sigma^{-2}_{e_1} & \hdots & \mathbf{0} & \mathbf{X}'_1\mathbf{Z}_1\sigma^{-2}_{e_1} & \hdots & \mathbf{0}\\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots\\
\mathbf{0} & \hdots & \mathbf{X}'_K\mathbf{X}_K\sigma^{-2}_{e_K} & \mathbf{0} & \hdots & \mathbf{X}'_K\mathbf{Z}_K\sigma^{-2}_{e_K}\\
\mathbf{Z}'_1\mathbf{X}'_1\sigma^{-2}_{e_1} & \hdots & \mathbf{0} & \mathbf{Z}'_1\mathbf{Z}_1\sigma^{-2}_{e_1}+\mathbf{I}_m\sigma^{11}_{\upbeta} & \hdots & \mathbf{I}_m\sigma^{1K}_{\upbeta}\\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots\\
\mathbf{0} & \hdots & \mathbf{Z}'_K\mathbf{X}'_K\sigma^{-2}_{e_K} & \mathbf{I}_m\sigma^{K1}_{\upbeta} & \hdots & \mathbf{Z}'_K\mathbf{Z}_K\sigma^{-2}_{e_K}+\mathbf{I}_m\sigma^{KK}_{\upbeta}\\
\end{bmatrix}
\begin{bmatrix}
\hat{\mathbf{b}}_1\\
\vdots\\
\hat{\mathbf{b}}_k\\
\hat{\mathbf{\upbeta}}_1\\
\vdots\\
\hat{\mathbf{\upbeta}}_K\\
\end{bmatrix}
=
\begin{bmatrix}
\sigma^{-2}_{e_1}\mathbf{X}'_1\mathbf{y}_1\\
\vdots\\
\sigma^{-2}_{e_K}\mathbf{X}'_k\mathbf{y}_K\\
\sigma^{-2}_{e_1}\mathbf{Z}'_1\mathbf{y}_1\\
\vdots\\
\sigma^{-2}_{e_K}\mathbf{Z}'_K\mathbf{y}_K
\end{bmatrix},
\end{equation}
where $\sigma^{ij}_{\upbeta}$ is the element at position $ij$ of $\mathbf{\Sigma}^{-1}_{\upbeta}$.

The iterative Gauss-Seidel method with residual updates, as presented in \cite{GSRU}, was used to solve the mixed-model equations without setting them up explicitly, while updating variances and covariances in each iteration. We define $\hat{\mathbf{e}} = [\hat{\mathbf{e}}_1~\hat{\mathbf{e}}_2~\hdots~\hat{\mathbf{e}}_K]$ to be the vector of estimated residuals, which was initialized as $\hat{\mathbf{e}}^{(0)} = [\mathbf{y}'_1~\mathbf{y}'_2~\hdots~\mathbf{y}'_K]$. The estimated fixed effect $j$ of environment $k$ was updated in iteration $t$ by:
\begin{equation}\nonumber
\label{eqn:MU1}
\hat{b}^{(t+1)}_{jk} = \frac{\mathbf{x}'_{jk}\hat{\mathbf{e}}_k}{
\mathbf{x}'_{jk}\mathbf{x}_{jk}},
\end{equation}
and before moving to the next fixed effect, the residual vector was updated by:
\begin{equation}\nonumber
\label{eqn:MU2}
\hat{\mathbf{e}}^{(new)}_k = \hat{\mathbf{e}}^{(old)}_k - \mathbf{x}_{jk}\hat{b}^{(t+1)}_{jk}.
\end{equation}

For updating estimated marker effects, $\hat{\dot{\mathbf{\upbeta}}}^{'(t)}_j = [\hat{\upbeta}^{(t)}_{j1}~\hat{\upbeta}^{(t)}_{j2}~\hdots~\hat{\upbeta}^{(t)}_{jK}]$ is defined as the vector of estimated marker effects for marker $j$ and all $K$ environments in iteration $t$, $\dot{\mathbf{Z}}_j = \oplus^{K}_{k=1} \mathbf{z}_{jk}$ as a matrix containing scores for marker $j$, $\mathbf{z}_{jk}$ as an $n_k$ column vector for scores at marker $j$ and environment $k$, and $\hat{\mathbf{\Sigma}}^{(t)}_{e} = Diag\{\hat{\sigma}^{2(t)}_{e_1},\hat{\sigma}^{2(t)}_{e_2},~\hdots~,\hat{\sigma}^{2(t)}_{e_K}\}$ as a diagonal matrix of estimated residual variances from all environments. Estimates of effects for marker $j$ were initialized to zero and updated by:
\begin{equation}%\nonumber
\label{eqn:GS_B}
\hat{\dot{\mathbf{\upbeta}}}^{(t+1)}_j = (\hat{\mathbf{\Sigma}}^{-1(t)}_{e}\dot{\mathbf{Z}}'_j\dot{\mathbf{Z}}_j + \hat{\mathbf{\Sigma}}^{-1(t)}_{\upbeta})^{-1} \hat{\mathbf{\Sigma}}^{-1(t)}_{e}\dot{\mathbf{Z}}'_j (\dot{\mathbf{Z}}_j\hat{\dot{\mathbf{\upbeta}}}^{(t)}_j+\hat{\mathbf{e}}),
\end{equation}
and before moving to the next marker, the residual vector is updated as:
\begin{equation}\nonumber
\label{eqn:GS_E}
\hat{\mathbf{e}}^{(new)} = \hat{\mathbf{e}}^{(old)} -  \dot{\mathbf{Z}}'_j(\hat{\dot{\mathbf{\upbeta}}}^{(t+1)}_j - \hat{\dot{\mathbf{\upbeta}}}^{(t)}_j).
\end{equation}

The term 
$\hat{\mathbf{\Sigma}}^{-1(t)}_{e}\dot{\mathbf{Z}}'_j\dot{\mathbf{Z}}_j$ of Eq. (\ref{eqn:GS_B}) is a $K\times K$ diagonal matrix with elements $\{\hat{\sigma}^{-2(t)}_{e1}\mathbf{z}'_{j1} \mathbf{z}_{j1}, ... , \hat{\sigma}^{-2(t)}_{eK}\mathbf{z}'_{jK} \mathbf{z}_{jK}\}$, and the term $\hat{\mathbf{\Sigma}}^{-1(t)}_{e}\dot{\mathbf{Z}}'_j(\dot{\mathbf{Z}}_j\hat{\dot{\mathbf{\upbeta}}}^{(t)}_j+\hat{\mathbf{e}})$ can be computed as a vector of length $K$ with elements $[ \hat{\sigma}^{-2(t)}_{e_1}(\mathbf{z}'_{j1} \mathbf{z}_{j1} \hat{\upbeta}^{(t)}_{j1} + \mathbf{z}_{j1}' \hat{\mathbf{e}}_1), ... , \hat{\sigma}^{-2(t)}_{e_K}(\mathbf{z}'_{jK} \mathbf{z}_{jK} \hat{\upbeta}^{(t)}_{jK} + \mathbf{z}_{jK}' \hat{\mathbf{e}}_K)]$. Values of $\mathbf{z}'_{jk} \mathbf{z}_{jk}$ were calculated before iterations start for all combinations of markers ($j$) and environments ($k$). 

To increase convergence rate, the order in which the marker effects are updated was randomized in each iteration. This approach is referred to as randomized Gauss-Seidel \cite{LL2010,Ma2015}.

\subsection{Solving variances and covariances}
Genetic variances and covariances were updated by using the method proposed by either \cite{VanRaden} or \cite{Schaeffer}, called \textsl{Tilde-Hat} (TH) and \textsl{Pseudo Expectation} (PE), respectively. Both methods use the quadratic form $\tilde{\mathbf{\upbeta}}'^{(t)}_k\hat{\mathbf{\upbeta}}^{(t)}_k$, 
where $\hat{\mathbf{\upbeta}}^{(t)}_k$ contains all estimated marker effects for environment $k$ in iteration $t$, and:
\begin{align}\label{BetaTilde}
 \tilde{\mathbf{\upbeta}}^{(t)}_k = \mathbf{D}^{-1(t)}_k\mathbf{Z}'_k \mathbf{M}_{k} \mathbf{y}_k.
\end{align}
The two methods differ in matrix $\mathbf{D}^{-1(t)}_k$. In PE, $\mathbf{D}^{(t)}_k = \mathbf{I}_m$, whereas in TH,
\begin{align}\label{MatrixD}
\mathbf{D}^{(t)}_k = Diag\{\mathbf{Z}_k'\mathbf{M}_k \mathbf{Z}_k\hat{\sigma}^{-2(t)}_{e_k}+\mathbf{I}_m\hat{\sigma}^{kk(t)}_{\upbeta}\},
\end{align}
which denotes a diagonal matrix, and $\mathbf{M}_{k}=\mathbf{I}_k-\mathbf{X}_{k} ( \mathbf{X}_{k}'\mathbf{X}_{k})^{-1} \mathbf{X}'_{k}$. As $\mathbf{D}^{(t)}_k$ is diagonal, $\mathbf{M}_{k}$ does not have to be explicitly generated, but only the diagonal
of $\mathbf{Z}'_{k} \mathbf{M}_{k} \mathbf{Z}_{k}$ needs to be computed once before iterations start and stored. This computation can be done efficiently, as shown in Appendix \ref{byPassM}. When the intercept is the only fixed effect, and both $\mathbf{y}_k$ and the columns of $\mathbf{Z}_k$ are centered, $\mathbf{M}_k$ can be omitted.
\\\\
Estimates of genetic and residual variances for environment $k$ were initialized to $\hat{\sigma}^{2(0)}_{\upbeta_k} = 0.5\cdot\sigma^2_{y_k}/(m\cdot\overline{\sigma^2}_{Z_k}$)
and $\hat{\sigma}^{2(0)}_{e_k} = 0.5\cdot\sigma^2_{y_k}$, respectively, where $\sigma^2_{y_k}$ is the sample variance of phenotypes and $\overline{\sigma^2}_{Z_k} = \frac{1}{m}\sum^m_{j=1}\sigma^2_{Z_{k_j}}$ is the average of marker-score variances across the $m$ columns of $\mathbf{Z}_k$. Estimates of genetic covariances were initialized to zero. The estimate of variance of marker effects for environment $k$ was updated by:
\begin{equation}
\label{eqn:SigmaBk}
\hat{\sigma}^{2(t+1)}_{\upbeta_k} = \frac{\tilde{\mathbf{\upbeta}}^{'(t)}_k\hat{\mathbf{\upbeta}}^{(t)}_k}{tr(\mathbf{D}^{-1(t)}_k \mathbf{Z}'_k \mathbf{M}_{k} \mathbf{Z}_k)},
\end{equation}
where $\mathbf{Z}_k$ contains marker scores for environment $k$, $tr(\cdot)$ is the trace operator, and $tr(\mathbf{D}^{-1(t)}_k \mathbf{Z}'_k \mathbf{M}_{k} \mathbf{Z}_k)$ is the expected value of $\tilde{\mathbf{\upbeta}}'^{(t)}_k\hat{\mathbf{\upbeta}}^{(t)}_k$, as derived in \cite{VanRaden} and in Appendix \ref{EVTH}. The 
estimate of the covariance between environments $k$ and $k'$ was updated by:
\begin{equation}
\label{eqn:SigmaBij}
\hat{\sigma}^{(t+1)}_{\upbeta_{kk'}} = \frac{\tilde{\mathbf{\upbeta}}^{'(t)}_k\hat{\mathbf{\upbeta}}^{(t)}_{k'} + \tilde{\mathbf{\upbeta}}^{'(t)}_{k'}\hat{\mathbf{\upbeta}}^{(t)}_k}{tr(\mathbf{D}^{-1(t)}_k \mathbf{Z}'_k \mathbf{M}_{k} \mathbf{Z}_k)+tr(\mathbf{D}^{-1(t)}_{k'} \mathbf{Z}'_{k'} \mathbf{M}_{k'} \mathbf{Z}_{k'})},
\end{equation}
as proposed by \cite{Schaeffer} and derived in Additional file 1, and residual variances were updated by
\begin{equation}
\label{eqn:SigmaEk}
\hat{\sigma}^{2(t+1)}_{e_k} = 
\frac{(\mathbf{M}_{k}\mathbf{y}_k)'\hat{\mathbf{e}}_k}{n_k-r_k}
\end{equation}
as in \cite{GSRU}, where $r_k$ is the number of linear independent columns of $\mathbf{X}_k$.
\\\\
Bending of $\hat{\Sigma}_{\upbeta}$ as described in \cite{bend0} was used after an iteration when it was not positive definite. The iterative scheme was repeated until a mean-squared convergence of $10^{-8}$ was reached for effects, variances, and covariances. The combination of the randomized Gauss-Seidel solver with either of the two methods for variance component estimation, i.e., TH or PE, is referred to here as THGS and PEGS, respectively. An implementation of PEGS is provided in the R package bWGR (2.0), function \textbf{mrr} \cite{bWGR}, and shown in Additional files 5 and 6.

\subsection{Exact THGS}

For balanced experimental designs, when the intercept is the only fixed effect, and either a principal components \cite{StatLearn} or eigenvector regression \cite{RKHS2010, svd2018, Xavier2021} is used, THGS is exact. This is demonstrated in Appendix \ref{ExactTH}. By either using a singular-value decomposition of $\mathbf{Z}_k$ or an eigenvalue decomposition (EVD) of $\mathbf{Z}'_k\mathbf{Z}_k$, a matrix of eigenvectors, $\mathbf{U}_k$, and a diagonal matrix of eigenvalues, $\mathbf{\Lambda}_k$, can be calculated. By fitting $\check{\mathbf{Z}}_k = \mathbf{Z}_k\mathbf{U}_k$  rather than $\mathbf{Z}_k$ in model (\ref{eqn:StatModel}), $\mathbf{Z}'_k\mathbf{M}_k\mathbf{Z}_k$ in Eq. (\ref{MatrixD})
becomes a diagonal matrix of eigenvalues, $\mathbf{\Lambda}_k$. Thus, $\mathbf{D}^{(t)}_k$ in Eqs. (\ref{eqn:SigmaBk}) and (\ref{eqn:SigmaBij}) can be written as:
\begin{align}\label{UNBIASEDTHGS}
 \mathbf{D}^{(t)}_k = \mathbf{\Lambda}_k\hat{\sigma}^{-2(t)}_{e_k}+\mathbf{I}_m\hat{\sigma}^{kk(t)}_{\upbeta}.
\end{align}
This does not apply to PEGS, because it uses $\mathbf{D}^{(t)}_k = \mathbf{I}_m$.


\subsection{Alternative methods}

As a gold standard for low biases and standard errors of both GEBVs and variance components, empirical genomic best linear unbiased predictions (GBLUP) \cite{GBLUP} were obtained by REML \cite{AIREML} for balanced experimental designs as follows. The genomic relationship matrix ($\mathbf{G}$) was diagonalized and the statistical model was transformed by the eigenvectors of an eigenvalue decomposition of $\mathbf{G}$ \cite{TS1990} (see Appendix \ref{AppGblup}). Eigenvectors of the smallest eigenvalues, which explained the last 1\% of the variation in $\mathbf{G}$ were neglected \cite{Pocrnic2016}. The transformed model was fitted using ASREML-R \cite{asreml}. For unbalanced experimental designs, ASREML 4.2, AIREMLF90 or REMLF90 did not return results for the full multivariate models in this simulation study. Thus, to obtain an upper bound of accuracy of GEBV, GBLUP were calculated using the true simulated variance components. This method was called true value Gauss-Seidel (TVGS).

Runtimes of the proposed and other methods were  compared only for balanced designs. In addition to the REML approach described above, $\mathbf{G}$ was used in its natural, dense form and 0.01 was added to its diagonal to render it positive definite. The expectation maximization (EM) REML algorithm of REMLF90 \cite{BLUPF90} and the average information (AI) REML algorithms of ASREML 4.2 \cite{AIREML,asreml} and AIREMLF90 \cite{YAMS} were used with their options for dense equations operations \textit{!gdense}  and \textit{use\_yams}, respectively. In addition, the Gibbs sampler of GIBBSF90 was run for comparison.

Univariate THGS (UV-THGS), which analyzes phenotypes of only one environment at a time with the randomised Gauss-Seidel solver and TH, was run to evaluate the increase in accuracy of GEBV with multivariate THGS over univariate THGS. Table \ref{METHODS} summarizes the methods used in this study.
\begin{table}[ht]
\centering
\renewcommand*{\arraystretch}{1.2}
\caption{Summary of methods used in the simulations.}\smallskip
\begin{tabular}{l c c c c c}
\hline
  & TVGS & PEGS & THGS & UV-THGS & REML  \\
\hline
Effect type in the model & Marker & Marker & Marker & Marker & Polygenic \\
Multivariate & Yes & Yes & Yes & No & Yes  \\
(Co)variance estimation$^{*}$ & True values & PE & TH & TH & REML  \\
Orthogonalization & No & No & No & No & Yes  \\
\hline
\multicolumn{5}{l}{\small *PE: pseudo expectation; TH: tilde-hat; REML: restricted maximum likelihood;}\\
\multicolumn{5}{l}{\small
TVGS: true-value Gauss-Seidel; PEGS: pseudo expectation Gauss-Seidel;}\\
\multicolumn{5}{l}{\small THGS: tilde-hat Gauss-Seidel; UV-THGS: univariate-tilde-hat Gauss-Seidel.}
\end{tabular}
\label{METHODS}
\end{table}

\subsection{Data and evaluation statistics}

Phenotypic data for five scenarios were simulated to evaluate bias and accuracy of GEBV within environments, runtime, and biases and standard errors of estimates of heritabilities and genetic correlations (Table \ref{SIMULATIONS}). The genotypes used in the simulations came from a wheat \cite{WheatData1,WheatData2,WheatData3,WheatData4} and a soybean dataset \cite{soynam3,soynam4,Xavier2021}, which have been used in multiple genomic prediction studies, and are available through the R packages BGLR and SoyNAM, respectively.

\textbf{Scenario 1} contained simulated phenotypes from inbred lines that were grown in the same ten environments, using 599 inbred lines from CIMMYT's Global Wheat Program \cite{WheatData1,WheatData2} that were genotyped at 1279 DArT markers \cite{DArT}. \textbf{Scenario 2} contained simulated phenotypes from different inbred lines grown in ten different environments, using 5142 recombinant inbred lines from the SoyNAM project \cite{soynam1,soynam2} genotyped for 4311 single nucleotide polymorphism (SNP) markers.  These lines were randomly allocated to ten different environments, and each line was observed in only one environment. \textbf{Scenario 3} was used to study the evaluation statistics for an increasing number of soy inbred lines in each of the ten environments. Thus, each line could be present in multiple environments. \textbf{Scenario 4} was used to study runtime of PEGS and THGS for an increasing number of environments (response variables), i.e., 10, 50, 100, 200 and 400, using the SoyNAM dataset with a random 10\% of lines missing in each environment. \textbf{Scenario 5} was used to study runtime with a higher marker density, using the SoyNAM dataset and genotyped at 42,034 SNPs that were obtained from the original SNPs plus from a linkage disequilibrium-based imputation of SNPs, as described in \cite{soynam2}.

\begin{table}[ht]
\centering
\renewcommand*{\arraystretch}{1.2}
\caption{Summary of simulated scenarios.}\smallskip
\begin{tabular}{l c c c c c}
\hline
 & Scenario 1  & Scenario 2 & Scenario 3 & Scenario 4 & Scenario 5\\
\hline
Number of environments (traits) & 10 & 10 & 10 & 10-400 & 10-400\\
Number of environments per line & 10 & 1 & 0-10 & 0-400 & 0-400 \\
Number of lines per environment & 599 & 514 & 250-3000 & 4628 & 4628\\
\% of lines per environment  & 100\% & 10\% & 5-60\% & 90\% & 90\% \\
Number of phenotypic records & 5990 & 51,420 & 30,000 & 1,851,120 & 1,851,120 \\
Number of markers & 1279 & 4311 & 4311 & 4311 & 42,034\\
Species & Wheat & Soy & Soy & Soy & Soy\\
\hline
\end{tabular}
\label{SIMULATIONS}
\end{table}

 Phenotypes were simulated by summing true genomic breeding values (TBV) and residuals. TBV for environment $k$ were sampled as $\mathbf{Z}\mathbf{\upbeta}_k$, where $\mathbf{Z}$ contains marker scores of inbred lines from all environments and the true marker effects in $\mathbf{\upbeta}_k$ were taken from $\mathbf{\upbeta}' = [\mathbf{\upbeta}'_1 ~ \mathbf{\upbeta}'_2 ~ \hdots \mathbf{\upbeta}'_K]$, which was sampled from $N(\mathbf{0}, \mathbf{\Sigma}_{\upbeta}\otimes \mathbf{I}_m$), where $\mathbf{\Sigma}_{\upbeta} = 
 \alpha^{-1}\mathbf{\Sigma}_{g}$, $\alpha = \sum^J_{j=1}{\sigma^2_{Z_j}}$,  $\sigma^2_{Z_j}$ is the variance of marker scores in $\mathbf{Z}$ at marker $j$, and $\mathbf{\Sigma}_{g}$ is the additive genetic variance-covariance matrix with 1 on the diagonal and genetic correlations on the off-diagonals. Residuals were sampled from $N(0,(1-h^2)h^{-2})$, where $h^2$ is the heritability in an environment. Three heritabilities  (0.2, 0.5, and 0.8) and three ranges of genetic correlations, low (0.2-0.4), medium (0.4-0.6), and high (0.6-0.8) were considered. Correlations were sampled from a uniform distribution within each range. Each simulation scenario was replicated 100 times.

Biases and standard errors of estimates of heritabilities and genetic correlations were calculated as the average and standard deviation, respectively, of estimated minus true simulated values across replicates. GEBV for environment $k$ were calculated as $\mathbf{Z}_k\hat{\mathbf{\upbeta}}_k$, and bias and accuracy of these GEBV were calculated as the regression coefficient of TBV on GEBV and as the correlation between TBV and GEBV, respectively.

\section{Results}

\subsection{Runtime}

The average runtimes for the different methods used in scenario 1 are presented in table \ref{RUNTIME1}. Multivariate PEGS and THGS took 0.4 and 0.3 seconds, respectively, univariate THGS aggregated across ten environments 0.2 seconds, and AI-REML using ASREML-R 3.3 seconds when the genomic relationship matrix was diagonalized by  eigenvalue decomposition. Standard implementations of REML based on the dense genomic relationship matrix ranged from 109.8 to 1250.7 seconds, whereas the Gibbs sampler took 559.8 seconds.

\begin{table}[ht]
\centering
\renewcommand*{\arraystretch}{1.2}
\caption{Average runtime in seconds (s.e.) for the balanced experimental design in scenario 1 based on 100 replicates of the simulation.}\smallskip
\begin{tabular}{l c c c}
\hline
Method$^1$ & Software & Model$^3$ & Runtime \\
\hline
PEGS & - & RR & 0.4 (0.0) \\
THGS & - & RR & 0.3 (0.0) \\
UV-THGS & - & RR & 0.2 (0.0) \\
AI-REML (EVD) & ASREML-R & GBLUP & 3.3 (0.3) \\
AI-REML & ASREML 4.2 & GBLUP & 272.6 (36.5) \\
AI-REML & AIREMLF90 & GBLUP & 109.8 (2.4) \\
EM-REML & REMLF90 & GBLUP & 1250.7 (11.7) \\
Gibbs sampling$^2$ & GIBBS3F90 & GBLUP & 559.8 (9.6) \\
\hline
\multicolumn{4}{l}{\small $^1$PEGS: pseudo expectation Gauss-Seidel; THGS: tilde-hat Gauss-Seidel;}\\
\multicolumn{4}{l}{\small UV-THGS: univariate-tilde-hat Gauss-Seidel; AI: average information;}\\
\multicolumn{4}{l}{\small REML: restricted maximum likelihood; EVD: eigenvalue decomposition; }\\
\multicolumn{4}{l}{\small{EM: expectation maximization; $^2$ 10,000 MCMC iterations;}}\\
\multicolumn{4}{l}{\small{ $^3$RR: ridge-regression; GBLUP: genomic best linear unbiased prediction.}}
\end{tabular}
\label{RUNTIME1}
\end{table}

Figure \ref{convergence} shows convergence of the Gauss-Seidel solver with and without  randomizing the order in which marker effects were updated for one replicate of scenario 2. The algorithm converged after 54 iterations with randomization, but required more than 3000 iterations without randomization.

\begin{figure}[ht]
  %\includegraphics[width=12cm]{Figure1_rgs.png}
  \caption{\small{Convergence of the Gauss-Seidel solver with (left) and without (right) randomizing the order in which marker effects were updated for one replicate of the simulation of scenario 2.}}
  \label{convergence}
\end{figure}

Table \ref{RUNTIME2} depicts average runtime in minutes for PEGS, THGS, and UV-THGS with and without randomizing the marker order in the Gauss-Seidel solver, as well as an increasing number of environments (scenario 4) and markers (scenario 5). The runtimes of PEGS and THGS were similar, and randomizing the marker order shortened runtimes. Without randomization, the multivariate models that fitted 42,034 SNPs did not converge within 2000 iterations.
Runtimes of PEGS and THGS increased exponentially with the number of environments from 0.2 minutes for ten environments to 448 minutes for 400 environments when using 4311 SNPs. Runtime of UV-THGS, in contrast, increased linearly from 0.1 to 4.3 minutes under the same conditions. With randomization, runtime increased with an increasing number of markers, from 0.2 minutes for 4311 SNPs to 0.8 minutes for 42,034 SNPs and ten environments, and from 80.5 to 123.2 minutes for 200 environments. Without randomization, runtime increased to 3057.3 minutes for 42,034 SNPs and 200 environments.

\begin{table}[ht]
\centering
\renewcommand*{\arraystretch}{1.2}
\caption{Average runtime in minutes (s.e.) of the Gauss-Seidel solver with and without randomizing the order of markers for updating marker effects, with increasing numbers of SNPs and environments, based on 10 replicates of scenarios 4 (4311 SNPs) and 5 (42,034 SNPs).}\smallskip
\begin{tabular}{c c c c c c c}
 \hline
 Randomized & Number of SNPs & Number of environments & PEGS & THGS & UV-THGS \\ 
 \hline
Yes &  4311 &  10 & 0.2 (0) & 0.2 (0) & 0.1 (0) & \\
Yes &  4311 &  50 & 3.5 (0.4) & 3.5 (0.4) & 0.6 (0) & \\
Yes &  4311 & 100 & 14.4 (2) & 14.4 (1.8) & 1.1 (0) & \\
Yes &  4311 & 200 & 80.5 (10.1) & 79.2 (11) & 2.3 (0.1) & \\
Yes &  4311 & 400 & 459.3 (55.1) & 448 (58) & 4.3 (0.1) & \\
No &  4311 &  10 & 5.5 (1) & 5.4 (0.9) & 1.9 (0.2) & \\
No &  4311 &  50 & 44.9 (7) & 44.6 (6.9) & 9.3 (1.1) & \\
No &  4311 & 100 & 120.9 (10.1) & 123.7 (9.9) & 20 (1.8) & \\
No &  4311 & 200 & 361.1 (48.9) & 364.6 (44.4) & 39.3 (2.8) & \\
No &  4311 & 400 & 1261.8 (115.8) & 1261.7 (107.9) & 74.1 (8.3) & \\
Yes & 42,034 &  10 & 0.8 (0.1) & 0.8 (0) & 1.2 (0.1) & \\
Yes & 42,034 &  50 & 9.9 (0.4) & 12.5 (1.3) & 5.7 (0.4) & \\
Yes & 42,034 & 100 & 36.4 (1.4) & 29.2 (2.7) & 11.3 (0.6) & \\
Yes & 42,034 & 200 & 123.2 (17.1) & 119.7 (10.1) & 22.5 (2) & \\
Yes & 42,034 & 400 & 730 (64.4) & 802.2 (118.2) & 46.4 (4.1) & \\
No & 42,034 &  10 & 64$^*$ (14.7) & 64.2$^*$ (16) & 14.5 (5.1) & \\
No & 42,034 &  50 & 540.2$^*$ (38.3) & 536$^*$ (26.8) & 106.5 (63.2) & \\
No & 42,034 & 100 & 1109.6$^*$ (71.5) & 1148.1$^*$ (109.3) & 181.4 (40.6) & \\
No & 42,034 & 200 & 3057.3$^*$ (292.7) & 3001.2$^*$ (259) & 310.3 (114.8) & \\
\hline
\multicolumn{6}{l}{\small PEGS: pseudo expectation Gauss-Seidel; THGS: tilde-hat Gauss-Seidel; UV-THGS: univariate-tilde-hat Gauss-Seidel.}\\
\multicolumn{6}{l}{\small{$^*$ Did not converge within 2000 iterations.}} \\
\end{tabular}
\label{RUNTIME2}
\end{table}

\subsection{Accuracy and bias of GEBV}

Accuracy of GEBV increased with increasing heritability and genetic correlation, as expected (Fig. \ref{Accuracy}). It was 0.03 to 0.09 higher for multivariate approaches than for univariate THGS when heritability was low and the genetic correlation was medium to high (Fig. \ref{Accuracy}, a and b, lower left panels). For most genetic parameters for scenario 1, REML provided a 0.01 higher accuracy than PEGS and THGS. For low heritability and low genetic correlations, however, REML resulted in a 0.02 higher accuracy and UV-THGS was as accurate as PEGS and THGS (Fig. \ref{Accuracy}a, upper left panel). The latter was also true for scenario 2. After additional simulations of scenario 1 for low heritability and low genetic correlations, accuracies of PEGS and THGS became larger than those of UV-GS and approached those of REML with increasing number of environments (Additional file 2, Figure S1).
Even REML tended to have lower accuracies for low heritability and low genetic correlation than TVGS (Fig. \ref{Accuracy}a, upper left panel). Differences for TVGS with both PEGS and THGS were similar for scenarios 1 and 2 (Fig. \ref{Accuracy} a vs. b). PEGS and THGS were not significantly different for scenarios 1 and 2.
\\\\
Regression coefficients of TBV on GEBV are shown in Fig. \ref{Slope}. For scenario 1 and low heritability, they were 1 for PEGS and THGS, close to 1 for REML, and significantly above 1 for UV-THGS. This bias for UV-THGS decreased with increasing heritability. For medium to high heritabilities, however, PEGS and THGS slightly underestimated (values $>$ 1) the TBV, while REML was usually unbiased, with a value of 1 (Fig. \ref{Slope}a). The bias for PEGS and THGS decreased with increasing genetic correlation. For scenario 2 (Fig. \ref{Slope}b), PEGS and THGS slightly overestimated TBV (values $<$1) for low heritability, but slightly underestimated TBV (values $>$1) for medium to high heritabilities. 

\begin{figure}[ht]
  %\includegraphics[width=12cm]{Figure2_acc.png}
  \caption{\small{Accuracy of GEBV for scenario 1 (a, wheat dataset) and scenario 2 (b, soybean dataset) for different true heritabilities (columns) and genetic correlations (rows), based on 100 replicates of the simulation. Letters indicate Tukey's test of multiple comparisons ($\alpha=0.05$).}}
  \label{Accuracy}
\end{figure}

\begin{figure}[ht]
  %\includegraphics[width=12cm]{Figure3_slope.png}
  \caption{\small{Regression of true breeding values on GEBV (slope) for scenario 1 (a, wheat dataset) and scenario 2 (b, soybean dataset) for different true heritabilities (columns) and genetic correlations (rows), based on 100 replicates of the simulation. Letters indicate Tukey's test of multiple comparisons ($\alpha=0.05$).}}
  \label{Slope}
\end{figure}

\subsection{Bias and standard error of parameters}

Figure \ref{FigBiasH2} shows the bias of estimates of heritabilities for scenarios 1 and 2 and different true genetic parameters. For both scenarios, estimates of heritabilities tended to be downward biased. For PEGS and THGS, the bias was smallest or even zero for low heritability and medium to high genetic correlations (Fig. \ref{FigBiasH2}, bottom left panels) and their biases decreased with increasing genetic correlations. The bias for UV-THGS tended to be lower than for PEGS and THGS. REML provided the least biased heritability estimates for scenario 1. 

\begin{figure}%[!ht]
  %\includegraphics[width=12cm]{Figure4_h2bias.png}
  \caption{\small{Bias of estimates of heritability for scenario 1 (a, wheat dataset) and scenario 2 (b, soybean dataset) for different true heritabilities (columns) and true genetic correlations (rows), based on 100 replicates of the simulation. Letters indicate Tukey's test  of multiple comparisons ($\alpha=0.05$). Asterisk indicates that the mean is significantly different from zero ($\alpha=0.05$).}}
  \label{FigBiasH2}
\end{figure}

Figure \ref{FigPrecH2} shows standard errors of estimates of heritabilities for scenarios 1 and 2 and different true genetic parameters. Standard errors were higher for scenario 1 than for scenario 2, higher for medium than for low and high heritabilities, highest for low genetic correlations, and decreased as the genetic correlation increased. Standard errors were 60 to 100\% higher for PEGS and THGS than for REML.

\begin{figure}%[!ht]
  %\includegraphics[width=12cm]{Figure5_h2se.png}
  \caption{\small{Standard error of estimates of heritability for scenario 1 (a, wheat dataset) and scenario 2 (b, soybean dataset) for different true heritabilities (columns) and true genetic correlations (rows), based on 100 replicates of the simulation. Letters indicate Tukey's test of multiple comparisons ($\alpha=0.05$).}}
  \label{FigPrecH2}
\end{figure}

Figures \ref{GCBIAS} and \ref{GCSE} show the bias and standard errors of estimates of genetic correlations for scenarios 1 and 2.  Bias tended to be low for PEGS and THGS for scenario 2, except for low heritability and high genetic correlations (Fig. \ref{GCBIAS}b, lower left panel). For scenario 1 and high genetic correlations (Fig. \ref{GCBIAS}a, lower left panel), REML had large biases, with absolute values of up to 0.08, compared to 0.01 for THGS. For low and medium true genetic correlations and for scenario 2, REML and the proposed methods had similar biases, and they were not significantly different for PEGS and THGS. As standard software for REML did not return results for the full model and the unbalanced designs for scenario 2, bivariate models were ran and the resulting estimates of the genetic correlations are given in Additional file 3.

\begin{figure}%[!ht]
  %\includegraphics[width=12cm]{Figure6_gcbias.png}
  \caption{\small{Bias of estimates of genetic correlation for scenario 1 (a, wheat dataset) and scenario 2 (b, soybean dataset) for different true heritabilities (columns) and true genetic correlations (rows), and based on 100 replicates of the simulation. Letters indicate Tukey's test of multiple comparison ($\alpha=0.05$). Asterisk indicates that the mean is significantly different from zero ($\alpha=0.05$).}}
  \label{GCBIAS}
\end{figure}

Standard errors of estimates of the genetic correlations decreased with increasing heritability and genetic correlations (Fig. \ref{GCSE}). Standard errors were always similar for PEGS and THGS, but higher than for REML for low to medium genetic genetic correlations. For high genetic correlations, standard errors were similar for all methods. Standard errors were lower for scenario 2 than for scenario 1.

\begin{figure}%[!ht]
  %\includegraphics[width=12cm]{Figure7_gcse.png}
  \caption{\small{Standard error of estimates of genetic correlations for scenario 1 (a, wheat dataset) and scenario 2 (b, soybean dataset) for different true heritabilities (columns) and true genetic correlations (rows), based on 100 replicates of the simulation. Letters indicate Tukey's test of multiple comparisons ($\alpha=0.05$). Asterisk indicates that the mean is significantly different from zero ($\alpha=0.05$).}}
  \label{GCSE}
\end{figure}

As the number of observations per environment increased in scenario 3, standard errors of estimates of genetic parameters decreased, bias of estimates of genetic correlations decreased, but bias of estimates of heritabilities did not approach zero even with 3000 observations per environment (Table \ref{VaryN}). Additional file 4 demonstrates the outcome when all 5142 lines were observed in all environments: heritabilities estimated with THGS were unbiased, and genetic correlations estimated with PEGS or THGS were unbiased.

\begin{table}[ht]
\centering
\renewcommand*{\arraystretch}{1.2}
\caption{Accuracy of GEBV, regression of TBV on GEBV (Slope), and bias and standard error (SE) of estimates of heritabilities ($\hat{h}^2$) and genetic correlations (GC) with increasing numbers of observations per environment (Obs/Env) in scenario 3, based on 100 replicates of the simulation. Standard errors of statistics are in parenthesis.}\smallskip
\begin{tabular}{l c c c c c c c}
 \hline
Method & Obs/Env & Accuracy & Slope & Bias of $\hat{h}^2$ & SE of $\hat{h}^2$ & Bias of GC& SE of GC \\
 \hline
PEGS & 250 & 0.82 (0.03) & 0.98 (0.03) & -0.01 (0.03) & 0.07 (0.01) & -0.01 (0.06) & 0.17 (0.02) \\
PEGS & 3000 & 0.96 (0.03) & 1.00 (0.03) & -0.01 (0.03) & 0.04 (0.01) & 0.00 (0.06) & 0.13 (0.02) \\
THGS & 250 & 0.82 (0.03) & 0.98 (0.04) & 0.00 (0.03) & 0.07 (0.01) & -0.02 (0.06) & 0.17 (0.02) \\
THGS & 3000 & 0.96 (0.03) & 1.00 (0.03) & -0.01 (0.03) & 0.04 (0.01) & 0.00 (0.06) & 0.13 (0.02) \\
UV-THGS & 250 & 0.79 (0.03) & 1.04 (0.03) & -0.01 (0.03) & 0.07 (0.01) & - & - \\
UV-THGS & 3000 & 0.95 (0.03) & 1.00 (0.04) & -0.01 (0.03) & 0.04 (0.01) & - & - \\
 \hline
\multicolumn{8}{l}{\small PEGS: pseudo expectation Gauss-Seidel; THGS: tilde-hat Gauss-Seidel;}\\
\multicolumn{8}{l}{\small UV-THGS: univariate-tilde-hat Gauss-Seidel.}\\
\end{tabular}
\label{VaryN}
\end{table}

\subsection{Orthogonalization}

Table \ref{ExTH} presents bias and accuracy of GEBV, as well as bias and standard errors of estimates of genetic parameters with and without using eigenvalue decomposition (EVD). THGS-EVD provided unbiased GEBV (Slope = 1) and its accuracy was 0.01 higher than for THGS and thus equal to the accuracy of REML. Estimates of the genetic correlations of THGS-EVD were unbiased and had lower standard errors than those obtained with THGS. The accuracy of GEBV from UV-THGS-EVD did not increase compared to that from UV-THGS, suggesting that the increase of accuracy for THGS-EVD resulted from a higher accuracy of estimates of genetic correlations. Biases and standard errors of estimates of genetic parameters, as well as biases and accuracies of GEBV were not different for PEGS and PEGS-EVD.

\begin{table}[ht]
\centering
\renewcommand*{\arraystretch}{1.2}
\caption{Accuracy of GEBV, regression of TBV on GEBV (Slope), and bias and standard error (SE) of estimates of heritabilities ($\hat{h}^2$) and genetic correlations (GC) with and without eigenvalue decomposition (EVD), based on 100 replicates of the simulation of scenario 1.}\smallskip
\begin{tabular}{l c c c c c c c }
\hline
Method & Accuracy & Slope  & Bias of $\hat{h}^2$ & SE of $\hat{h}^2$ & Bias of GC & SE of GC   \\
\hline
REML-EVD & 0.87 (0.02) & 1.00 (0.03) & -0.01 (0.02) & 0.04 (0.01) & 0.00 (0.04) & 0.14 (0.03) \\
PEGS & 0.86 (0.02) & 1.02 (0.03) & -0.03 (0.04) & 0.07 (0.02) & 0.02 (0.08) & 0.18 (0.04) \\
PEGS-EVD & 0.86 (0.02) & 1.02 (0.03) & -0.04 (0.04) & 0.07 (0.02) & 0.02 (0.08) & 0.18 (0.04) \\
THGS & 0.86 (0.02) & 1.02 (0.03) & -0.03 (0.04) & 0.07 (0.02) & 0.01 (0.08) & 0.17 (0.04) \\
THGS-EVD & 0.87 (0.02) & 1.00 (0.03) & -0.02 (0.03) & 0.05 (0.01) & 0.00 (0.04) & 0.13 (0.02) \\
UV-THGS & 0.84 (0.04) & 1.06 (0.09) & -0.02 (0.05) & 0.08 (0.02) & - & - \\
UV-THGS-EVD & 0.84 (0.03) & 1.03 (0.04) & -0.03 (0.03) & 0.05 (0.01) & - & - \\
\hline
\multicolumn{7}{l}{\small REML: restricted maximum likelihood; EVD: eigenvalue decomposition; }\\
\multicolumn{7}{l}{\small PEGS: pseudo expectation Gauss-Seidel; THGS: tilde-hat Gauss-Seidel;}\\
\multicolumn{7}{l}{\small UV-THGS: univariate-tilde-hat Gauss-Seidel}\\
\end{tabular}
\label{ExTH}
\end{table}


\section{Discussion}

Our main goal was to develop an algorithm for multivariate genomic prediction that is efficient in runtime and memory, applicable to unbalanced experimental designs, and exploits genetic correlations between environments to increase the accuracy of GEBV compared to univariate analyses. We proposed two algorithms, PEGS and THGS, that use randomized Gauss-Seidel to estimate marker effects and simultaneously estimate variance components, based on methods developed by \cite{Schaeffer} and \cite{VanRaden}, respectively. Simulations were conducted to evaluate bias and accuracy of GEBV within environment and to compare them to those obtained by REML and a univariate approach. Bias and standard errors of estimates of heritabilities and genetic correlations were also evaluated to interpret the differences in bias and accuracy of GEBVs between methods (Table \ref{METHODS}).

PEGS and THGS were shown to be fast and memory-efficient algorithms for both balanced and unbalanced experimental designs, and had a much shorter runtime than REML using standard software implementations (Tables \ref{RUNTIME1} and \ref{RUNTIME2}). Moreover, PEGS and THGS are scalable with the number of environments and markers. The reasons for the speed and efficiency of PEGS and THGS are that equations are solved by randomized Gauss-Seidel and that expectations of quadratic forms, shown in the denominator of Eqs. (\ref{eqn:SigmaBk}) and (\ref{eqn:SigmaBij}), are inexpensive to compute. These expectations do not require elements of the inverse of the left-hand side of the mixed-model equations as shown in \cite{Schaeffer}. Therefore, the system of equations essentially reduces to a $K\times K$ problem (Eq. (\ref{eqn:GS_B})) with complexity $O(K^3)$. When fitting hundreds to thousands of response variables, it is possible to linearize operations through full-conditional multivariate Gauss-Seidel algorithm presented in Appendix \ref{UVMVsol}.

The number of iterations to convergence (Fig. \ref{convergence}) and runtime of PEGS and THGS decreased greatly by randomizing the marker order for updating marker effects (Table \ref{RUNTIME2}). This may be because randomization reduces dependencies of consecutively updated markers that stem from high linkage disequilibrium between adjacent markers on the same chromosome. With an increasing number of environments and markers, PEGS and THGS had reasonably short runtimes (Table \ref{RUNTIME2}, with randomization), which allows breeders to make decisions on time, and rerun genetic evaluations as data become available during harvest season.

For balanced designs, the number of iterations to convergence can be further reduced by modeling the eigenvectors of genotype scores, which completely removes dependencies among model effects. In addition, THGS becomes an exact method that yields unbiased estimates of genetic correlations and GEBV (section Exact THGS), and reduces the bias of estimates of heritabilities, as can be demonstrated for scenario 1 (Table \ref{ExTH}). Matrix decomposition is also useful to analyze high-dimensional datasets with many factors ($P>>N$ problem), and to fit one or multiple kernels of different types within multivariate ridge regression models, for example, for modeling dominance, epistasis \cite{Xu2013}, and Gaussian or Arc-cosine relationships \cite{Xavier2021,Kernel2021}. The computing costs for matrix decomposition to obtain those eigenvectors, however, may outweigh the benefits for THGS as the  number of individuals and markers in the analysis increases.

The trade-off for higher speed with PEGS and THGS is a slightly lower accuracy of GEBV of 0.01 compared to REML under realistic conditions when heritability was low and genetic correlations between environments were medium to high (Fig. \ref{Accuracy}a). PEGS and THGS exploited genetic correlations between environments under these conditions and had a higher accuracy of GEBV than the univariate approach (Fig. \ref{Accuracy}a and b). Only in the worst case, when all heritabilities and all genetic correlations between environments were low, did the benefit in accuracy of multivariate genomic prediction over the univariate approach vanish with PEGS and THGS (Fig. \ref{Accuracy}a and b). This occurred because PEGS and THGS resulted in notably higher standard errors of estimates of genetic correlations than REML (Fig. \ref{GCSE}). Moreover, PEGS and THGS slightly underestimated heritabilities and slightly overestimated genetic correlations. The bias of GEBVs, however, was close to zero and approached zero with an increasing number of lines per environment (Fig. \ref{Slope}, Table \ref{VaryN}, Appendix \label{AppTab}).

Residuals were treated as uncorrelated between environments for three reasons. First, the phenotypes come from different individuals that are assumed to have uncorrelated environmental effects. Second, epistatic effects, which are not captured by the marker effects in the model of Eq. (\ref{eqn:StatModel}), are assumed to have small covariances between environments. Third, the PEGS and THGS algorithms are faster because the absorption matrix $\mathbf{M}$, which is used in Eqs. (\ref{BetaTilde}) to (\ref{eqn:SigmaEk}), is block-diagonal with one block per environment, $\mathbf{M}_k$. And finally, fewer computations are required to update estimated marker effects when the residual covariance matrix is diagonal (see Eq. (\ref{eqn:GS_B})). If phenotypes come from multiple quantitative traits, residual covariances may need to be modeled to avoid further bias in the estimated genetic parameters and GEBV, which may increase runtime \cite{Schaeffer} and offset the computational advantage compared to REML. However, these covariances could be modeled with an additional random term that is constructed by the cross-product of sparse 0/1-incidence matrices for genotypes from different environments. Otherwise, the effect of neglecting the residual covariances on bias of estimates of genetic parameters and GEBV could be evaluated on a case-by-case basis.

Estimates of variances and covariances obtained by the methods PE and TH are unbiased when the mixed-model equations are weighted by the true variances and covariances as shown in Additional files 1 and 5, and Appendix \ref{EVTH}. In practice, however, an iterative procedure starts with best guesses for genetic parameters and, thus, estimates are not expected to be unbiased, which is the same for REML or iterative MIVQUE \cite{Searle1992}. As discussed in \cite{VanRaden}, estimates may be further biased when populations are under selection. In plant breeding, data are analyzed by breeding stage and thereby do not contain selection information, otherwise may be augmented with unselected genotypes \cite{HabierOpt2013,Rincent2017}. Yet, Ouweltjes et al. \cite{Ouweltjes1988} and VanRaden and Jung \cite{VanRaden} found that PE can be more suitable than TH to estimate variance components in populations under selection, but both methods were found to be slightly more biased than REML. These studies were performed using pedigree information and the bias was attributed to neglecting off-diagonals of the relationship matrix. To better understand this, the original quadratic form, $\hat{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k$, can be compared to $\tilde{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k$ from Eq. (\ref{eqn:SigmaBk}). For simplicity, only the univariate case and the method PE with $\tilde{\mathbf{\upbeta}}_k = \mathbf{Z}'_k\mathbf{M}_{k} \mathbf{y}_k$ is considered here. Using BLUP formulas \cite{Searle1992}, the quadratic forms can be written as:
\begin{align}\label{QFORMS1}
    \hat{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k &= (\mathbf{y}_k-\mathbf{X}\hat{\mathbf{b}}_{\textrm{GLS}_k})'\mathbf{V}^{-1}_k\mathbf{Z}_k\sigma^2_{\upbeta_k}\sigma^2_{\upbeta_k}\mathbf{Z}'_k\mathbf{V}^{-1}_k(\mathbf{y}_k-\mathbf{X}\hat{\mathbf{b}}_{\textrm{GLS}_k}),
\end{align}
and
\begin{align}\nonumber
    \tilde{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k &= \mathbf{y}'_k\mathbf{M}_k\mathbf{Z}_k
    \hat{\mathbf{\upbeta}}_k\\\label{QFORMS2}
    &= (\mathbf{y}_k-\mathbf{X}\hat{\mathbf{b}}_{\textrm{LS}_k})'\mathbf{Z}_k\sigma^2_{\upbeta_k}\mathbf{Z}'_k\mathbf{V}^{-1}_k(\mathbf{y}_k-\mathbf{X}\hat{\mathbf{b}}_{\textrm{GLS}_k}),
\end{align}
where $\mathbf{V}^{-1}_k$ is the inverse of the variance-covariance matrix of $\mathbf{y}_k$, $\mathbf{V}_k = \mathbf{Z}_k\mathbf{Z}'_k\sigma^2_{\upbeta_k}+\mathbf{I}\sigma^2_{e_k}$, and $\hat{\mathbf{b}}_{\textrm{GLS}_k}$ and $\hat{\mathbf{b}}_{\textrm{LS}_k}$ are the generalized least squares and least squares estimators, respectively, of $\mathbf{b}$. Thus in $\tilde{\mathbf{\upbeta}}_k$, the matrix $\mathbf{V}^{-1}_k$, which contains genomic relationships between individuals, i.e., $\mathbf{Z}_k\mathbf{Z}'_k$, is not used to weigh $\mathbf{y}_k$, or to estimate fixed effects ($\hat{\mathbf{b}}_{\textrm{LS}_k}$) or random effects. However, THGS in combination with principal components or eigenvector regression provides the exact estimates of variance and covariance components for populations under selection.

PEGS and THGS should be evaluated against alternative methods for modeling phenotypes from multiple environments. These are compound symmetry and extended factor analytic (XFA) models \cite{MeyerXFA}. Compound symmetry models fit a term for the average genetic effect of an individual across environments and another term for the specific environmental effects for an individual. As each term is modeled with only one variance, this model assumes that the genetic correlations between all pairs of environments are identical. The difference between that single correlation and the true correlation between any pair of environments can be regarded as bias. The XFA model fits more parameters than the compound symmetry model to reduce this bias, but less parameters than an unstructured multivariate model that fits a correlation for each pair of environments, and thus balances bias and precision of estimated genetic correlations. Therefore, these two alternative models tend to bias estimates of genetic correlations between environments and are expected to decrease accuracy of GEBV compared to estimating genetic correlations between all pairs of environments, unless the amount of genetic information is limited.

The iterative algorithm of PEGS and THGS differs from that of REML and Bayesian Gibbs sampling. In each iteration of REML, the mixed-model equations are fully solved to obtain estimates of the model effects conditional on the current variance components of that iteration. The estimated model effects are then used to update the variance components and a new iteration begins, unless the change in variance components is small. In PEGS and THGS, in contrast, the model effects are merely updated, not solved, before variance components are updated and a new iteration begins. In Bayesian Gibbs sampling, similar computations are conducted in each iteration as in PEGS and THGS. However, rather than converging directly to a solution within a small number of iterations, the Gibbs algorithm samples from the posterior for thousands of iterations and, therefore, must have longer runtimes. 

\section{Conclusions}

PEGS and THGS are fast, memory-efficient, and reliable algorithms for genomic prediction for both balanced and unbalanced experimental designs. They are scalable with an increasing number of response variables and markers. Their runtime is much shorter than for REML and Gibbs sampling. For balanced designs, THGS provides unbiased GEBV and estimates of genetic correlations if only an intercept is modeled, and eigenvalue decomposition is feasible. Without eigenvalue decomposition, the accuracy of GEBV obtained using PEGS and THGS is slightly lower than of GEBV obtained using REML, but higher than that of univariate THGS under realistic genetic correlations between environments. Estimates of genetic parameters obtained using PEGS and THGS have little bias, but their standard errors are larger than for REML. More studies are needed to evaluate the PEGS and THGS algorithms for unbalanced datasets with selection. 

\begin{backmatter}

\section*{Ethics approval and consent to participate}
Not applicable.

\section*{Consent for publication}
Not applicable.

\section*{Availability of data and materials}
Genotypic data of the wheat dataset are available in the R package BGLR using the command \verb|data(wheat,package="BGLR")|, and genotypic data of the SoyNAM dataset are available in the R package SoyNAM using the command \verb|data <- SoyNAM::ENV()|. An implementation of PEGS is provided in the R package bWGR (version 2.0), function \verb|mrr|.

\section*{Competing interests}
The authors declare that they have no competing interests.

\section*{Funding}
The authors are salaried researchers. No particular funding was provided for this research. 

\section*{Author's contributions}
AX and DH developed the methods, implemented the algorithms, planned the validations, wrote the manuscript. Both authors read and approved the final manuscript.

\section*{Acknowledgements}

We thank Rohan Fernando for his influential work that has served as foundation for the present study. In particular, all his theoretical contributions to our understanding of molecular information and genetic relationships, various regression methods, and models of heterogeneous populations that have paved the way to modern genomic prediction. DH is deeply grateful to Rohan for being a wonderful teacher, mentor, and friend. He has changed the career path of DH.

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
%\\ \bibliography{bmc_article}      % Bibliography file (usually '*.bib' )
% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
%\nocite{label}

\bibliography{bmc_article}

\newpage

\end{backmatter}

\appendix

\section{Efficient calculation of $\mathbf{Z}'_{k} \mathbf{M}_{k} \mathbf{Z}_{k}$ and  $\mathbf{M}_{k}\mathbf{y}_k$\label{byPassM}}

Only the diagonal elements of  $\mathbf{Z}'_{k} \mathbf{M}_{k} \mathbf{Z}_{k}$ are needed as matrix $\mathbf{D}_k$ is diagonal (Eq. (\ref{MatrixD})). They can be computed one at a time for environment $k$ and marker $j$ as:
\begin{equation}\nonumber
\label{eqn:TrZMZ}
\mathbf{z}'_{jk} \mathbf{M}_{jk} \mathbf{z}_{k}  = \mathbf{z}_{jk}'\mathbf{z}_{jk} - \mathbf{z}_{jk}'\mathbf{X}_{k}(\mathbf{X}'_{k} \mathbf{X}_{k})^{-1} \mathbf{X}'_{k} \mathbf{z}_{jk}
\end{equation}
where $(\mathbf{X}'_{k} \mathbf{X}_{k})^{-1}$ is computed once before iterations start. Likewise, $\mathbf{M}_{k}\mathbf{y}_k$ of Eq. (\ref{eqn:SigmaEk}) can be obtained once as:
\begin{equation}\nonumber
\label{eqn:My}
\mathbf{M}_{k}\mathbf{y}_k = \mathbf{y}_k - \mathbf{X}_{k}(\mathbf{X}'_{k} \mathbf{X}_{k})^{-1} \mathbf{X}'_{k} \mathbf{y}_k = \mathbf{y}_k - \mathbf{X}_{k} \mathbf{\hat{b}}_{LS_k},
\end{equation}
where $\mathbf{\hat{b}}_{LS_k}$ denotes the Least Squares estimate of $\mathbf{b}$.


\section{Expected value of $\tilde{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k$\label{EVTH}}

Let $\tilde{\mathbf{\upbeta}}_k = \mathbf{D}^{-1}_k\mathbf{Z}'_k\mathbf{M}_k\mathbf{y}_k$ and $\mathbf{M}_k = \mathbf{I}_k - \mathbf{X}_k(\mathbf{X}'_k\mathbf{X}_k)^{-1}\mathbf{X}_k$, as defined in the section \textsl{Solving variances and covariances}, and let $\hat{\mathbf{\upbeta}}_k = \sigma^2_{\upbeta_k}\mathbf{Z}'_k\mathbf{P}_k\mathbf{y}_k$ be the best linear unbiased predictor (BLUP) of $\mathbf{\upbeta}$ \cite{Searle1992}, where $\mathbf{P}_k = \mathbf{V}^{-1}_k[\mathbf{I}_k-\mathbf{X}_k(\mathbf{X}'_k\mathbf{V}^{-1}_k\mathbf{X}_k)^{-1}\mathbf{X}_k\mathbf{V}^{-1}_k]$ and $E(\hat{\mathbf{\upbeta}}) = \mathbf{0}$. Then, the expected value of the bilinear form  $\tilde{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k$ \cite{Searl71} is:
\begin{align*}
    E(\tilde{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k) &= tr(Cov(\tilde{\mathbf{\upbeta}}_k, \hat{\mathbf{\upbeta}}'_k)) + E(\tilde{\mathbf{\upbeta}}_k)'E(\hat{\mathbf{\upbeta}}_k)\\
    &= tr(\mathbf{D}^{-1}_k\mathbf{Z}'_k\mathbf{M}_k\mathbf{V}_k\mathbf{P}_k\mathbf{Z}_k\sigma^2_{\upbeta_k})\\
    &= tr(\mathbf{D}^{-1}_k\mathbf{Z}'_k\mathbf{M}_k\mathbf{Z}_k)\sigma^2_{\upbeta_k},
\end{align*}
because $\mathbf{M}_k\mathbf{V}_k\mathbf{P}_k = \mathbf{M}_k$. Hence, 
\begin{align*}
    \hat{\sigma}^2_{\upbeta_k} &= \frac{\tilde{\mathbf{\upbeta}}'_k\hat{\mathbf{\upbeta}}_k}{tr(\mathbf{D}^{-1}_k\mathbf{Z}'_k\mathbf{M}_k\mathbf{Z}_k)},
\end{align*}
and $E(\hat{\sigma}^2_{\upbeta_k}) = \sigma^2_{\upbeta_k}$. The extension to using $\hat{\mathbf{\upbeta}}_k$ from a multivariate BLUP is presented in Additional file 1.

\section{Equivalence of $\hat{\mathbf{\upbeta}}$ and $\tilde{\mathbf{\upbeta}}$ using EVD} \label{ExactTH}

Let the eigenvalue decomposition of $\mathbf{Z}'_k\mathbf{Z}_k$ be
$\mathbf{U}_k\mathbf{\Lambda}_k\mathbf{U}'_k$, where $\mathbf{U}_k$ is an orthonormal matrix of eigenvectors with the property $\mathbf{U}'_k\mathbf{U}_k = \mathbf{U}_k\mathbf{U}'_k = \mathbf{I}_m$, and $\mathbf{\Lambda}_k$ is a diagonal matrix of eigenvalues. The principal component regression \cite{StatLearn} can be written as:
\begin{align*}
    \mathbf{y}_k &= \mathbf{1}\mu_k + \mathbf{Z}_k\mathbf{U}_k\mathbf{U}'_k\mathbf{\upbeta}_k + \mathbf{e}_k\\
    &= \mathbf{1}\mu_k +\check{\mathbf{Z}}_k\check{\mathbf{\upbeta}}_k + \mathbf{e}_k,
\end{align*}
where $\tilde{\mathbf{Z}}_k = \mathbf{Z}_k\mathbf{U}_k$ and $\check{\mathbf{\upbeta}}_k = \mathbf{U}'_k\mathbf{\upbeta}_k$. Let the estimate of $\check{\mathbf{\upbeta}}_k$ be $\tilde{\mathbf{\upbeta}}_k = \mathbf{D}^{-1}_k\check{\mathbf{Z}}'_k\mathbf{y}_k$ similar to Eq. (\ref{UNBIASEDTHGS}), where $\mathbf{M}_k$ was omitted because $\mathbf{Z}_k$ and $\mathbf{y}_k$ are assumed centered. Then, defining $\lambda_k = \sigma^2_{e_k}/\sigma^2_{\upbeta_k}$, and using $(\mathbf{U}_k)^{-1} = \mathbf{U}'_k$ and $(\mathbf{U}'_k)^{-1} = \mathbf{U}_k$,
\begin{align*}
    \hat{\mathbf{\upbeta}}_k &= (\mathbf{Z}'_k\mathbf{Z}_k + \mathbf{I}_m\lambda_k)^{-1}\mathbf{Z}'_k\mathbf{y}_k\\
    &= \mathbf{U}_k\tilde{\mathbf{\upbeta}}_k\\
    &= \mathbf{U}_k\mathbf{D}^{-1}_k\check{\mathbf{Z}}'_k\mathbf{y}_k\\
    &= \mathbf{U}_k(\mathbf{\Lambda}_k+\mathbf{I}_m\lambda_k)^{-1}\check{\mathbf{Z}}_k\mathbf{y}_k\\
    &= \mathbf{U}_k[\mathbf{U}'_k\mathbf{U}_k(\mathbf{\Lambda}_k+\mathbf{I}_m\lambda_k)\mathbf{U}'_k\mathbf{U}_k]^{-1}\check{\mathbf{Z}}'_k\mathbf{y}_k\\
    &= \mathbf{U}_k[\mathbf{U}'_k(\mathbf{U}_k\mathbf{\Lambda}_k\mathbf{U}'_k+\mathbf{I}_m\lambda_k)\mathbf{U}_k]^{-1}\check{\mathbf{Z}}'_k\mathbf{y}_k\\
    &= \mathbf{U}_k\mathbf{U}'_k(\mathbf{Z}'_k\mathbf{Z}_k+\mathbf{I}_m\lambda_k)^{-1}\mathbf{U}_k\tilde{\mathbf{Z}}'_k\mathbf{y}_k\\
    &= (\mathbf{Z}'_k\mathbf{Z}_k+\mathbf{I}_m\lambda_k)^{-1}\mathbf{U}_k\mathbf{U}'_k\mathbf{Z}'_k\mathbf{y}_k\\
    &= (\mathbf{Z}'_k\mathbf{Z}_k+\mathbf{I}_m\lambda_k)^{-1}\mathbf{Z}'_k\mathbf{y}_k.
\end{align*}

\section{Polygenic model using EVD} \label{AppGblup}
The model can be written as:
\begin{equation}\label{POLYMODEL}
    \mathbf{y} = \mathbf{X}\mathbf{b} + \mathbf{g} + \mathbf{e},
\end{equation}
where $\mathbf{y}$, $\mathbf{X}$, $\mathbf{b}$, and $\mathbf{e}$ are defined as in the section \textsl{statistical model}, and $\mathbf{g}$ is a vector of breeding values that can be partitioned into $\mathbf{g}' = [\mathbf{g}'_1 ~\mathbf{g}'_2 ~\hdots ~\mathbf{g}'_K$]. It is assumed to be multivariate normal-distributed with mean zero and variance $\mathbf{\Sigma}_g\otimes\mathbf{G}$, where $\mathbf{\Sigma}_g$ is a $K$ x $K$ variance-covariance matrix of breeding values for $K$ environments and $\mathbf{G}$ is the genomic relationship matrix. The eigenvalue decomposition of this matrix can be written as $\mathbf{G} = \mathbf{U}\mathbf{\Lambda}\mathbf{U}'$, where $\mathbf{U}$ contains orthogonal eigenvectors and $\mathbf{\Lambda}$ is a diagonal matrix that contains eigenvalues. To diagonalize $\mathbf{G}$, model (\ref{POLYMODEL}) was tranformed by $\mathbf{T} = \mathbf{1}_K\otimes\mathbf{U}'$, where $\mathbf{1}_K$ is a $K$ vector of 1s, hence:
\begin{align*}
    \mathbf{T}\mathbf{y} &= \mathbf{T}\mathbf{X}\mathbf{b} + \mathbf{T}\mathbf{g} + \mathbf{T}\mathbf{e}\\
     &= \tilde{\mathbf{X}}\mathbf{b} + \tilde{\mathbf{g}} + \tilde{\mathbf{e}},
\end{align*}
where $\tilde{\mathbf{g}}\sim N(\mathbf{0}, \mathbf{\Sigma}_g\otimes\mathbf{\Lambda})$ and $\tilde{\mathbf{e}}\sim N(\mathbf{0}, \oplus^K_{i=1}\mathbf{I}\sigma^2_{e_k})$.

\section{Full-conditional Gauss-Seidel solution \label{UVMVsol}}

Equation (\ref{eqn:GS_B}) can be rearranged to reduce the multivariate Gauss-Seidel solver into a univariate algorithm, as an extension of the algorithm in \cite{GSRU}. This circumvents the inverse in Eq. (\ref{eqn:GS_B}), but may have slower convergence. The estimated effect of marker $j$ and environment $k$ is updated as:
\begin{equation} \nonumber
\hat{\upbeta}^{(t+1)}_{jk}|\hat{\mathbf{\upbeta}}^{(t)}_j,\hat{\mathbf{\Sigma}}_\upbeta = \frac{ \mathbf{z}_{jk}'\hat{\mathbf{e}}_k + \mathbf{z}'_{jk}  \mathbf{z}_{jk} \hat{\upbeta}_{jk}^{(t)} - \hat{\sigma}^{2}_{e_k}\sum^K_{l=1, l\ne k}\hat{\mathbf{\Sigma}}^{-1}_{\upbeta_{kl}}\cdot\hat{\upbeta}^{(t)}_{jl}}{ \mathbf{z}_{jk} ' \mathbf{z}_{jk} + \hat{\sigma}^2_{e_k}\hat{\sigma}_\upbeta^{kk} }
\end{equation}
where $\hat{\sigma}_\upbeta^{kk}$ is the $kk$ element of $\hat{\mathbf{\Sigma}}^{-1}_\upbeta$.
The update of $\hat{\upbeta}^{(t+1)}_{jk}$ is followed by the update of residuals of environment $k$ as:
\begin{equation} \nonumber
\hat{\mathbf{e}}^{(new)}_k = \hat{\mathbf{e}}^{(old)}_k-\mathbf{z}_{jk}(\hat{\upbeta}_{jk}^{(t+1)}-\hat{\upbeta}_{jk}^{(t)}).
\end{equation}



\end{document}

%where $\mathbf{v}'$ denotes the $k^{th}$ row of $\hat{\mathbf{\Sigma}}^{-1}_\upbeta$ except for element $k$, and $\mathbf{u}$ denotes a (K-1)-column vector of marker effects of $\hat{\mathbf{\upbeta}}^{(t)}_{j}$, except for element $k$, and